<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Distributed Systems on </title>
    <link>https://poorlydefinedbehaviour.github.io/categories/distributed-systems/</link>
    <description>Recent content in Distributed Systems on </description>
    <image>
      <title></title>
      <url>https://poorlydefinedbehaviour.github.io/papermod-cover.png</url>
      <link>https://poorlydefinedbehaviour.github.io/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.132.1</generator>
    <language>en</language>
    <lastBuildDate>Thu, 15 Aug 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://poorlydefinedbehaviour.github.io/categories/distributed-systems/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Model checking The Deadlock Empire</title>
      <link>https://poorlydefinedbehaviour.github.io/posts/the_deadlock_empire/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://poorlydefinedbehaviour.github.io/posts/the_deadlock_empire/</guid>
      <description>This post contains TLA+ solutions for The Deadlock Empire which is a collection of challenges where the objective is to break multithreaded programs by playing the role of a scheduler that can context switch at any time.
Non atomic instructions
There&amp;rsquo;s two threads executing the following code:
a = a + 1; if (a == 1) { critical_section(); } Since the a increment is not atomic, conceptually, it is like setting a temporary variable to the value of a&amp;ndash; tmp = a and then setting a to the temporary variable value incremented by 1 &amp;ndash; a = tmp + 1.</description>
    </item>
    <item>
      <title>Consistent hashing</title>
      <link>https://poorlydefinedbehaviour.github.io/posts/consistent_hashing/</link>
      <pubDate>Fri, 06 Oct 2023 20:00:00 -0300</pubDate>
      <guid>https://poorlydefinedbehaviour.github.io/posts/consistent_hashing/</guid>
      <description>As the World Wide Web became more popular all of sudden a server could receive way more traffic than it could handle causing the server to service requests slowly or to not be able to serve them at all1. An intuitive solution to this problem is to cache2 the content served by the servers and allow the clients to fetch content from the caches instead of going to the original server.</description>
    </item>
    <item>
      <title>Thinking about failure, fair-loss links and two generals</title>
      <link>https://poorlydefinedbehaviour.github.io/posts/fair_loss_links_and_two_generals/</link>
      <pubDate>Tue, 28 Mar 2023 20:30:00 -0300</pubDate>
      <guid>https://poorlydefinedbehaviour.github.io/posts/fair_loss_links_and_two_generals/</guid>
      <description>It feels like most people are not used to thinking about how things can fail, programming as if things always work as expected is the default modus operandi of most engineers i have talked to. Some examples that come to mind: http requests without handling responses that don&amp;rsquo;t have status 200, no timeouts, no retries, publishing a message to kafka and them updating a database, having a web client orchestrate a transaction across several systems without thinking: what if the user closes the browser tab?</description>
    </item>
    <item>
      <title>Logs</title>
      <link>https://poorlydefinedbehaviour.github.io/posts/logs/</link>
      <pubDate>Sat, 30 Apr 2022 16:46:09 -0300</pubDate>
      <guid>https://poorlydefinedbehaviour.github.io/posts/logs/</guid>
      <description>What is a log A log is just a immutable sequence of records wih strong ordering semantics that can be used to provide durability, replication and to model consensus. It is usually a 0 indexed file that new entries are appended to because expensive disk seeks can usually be avoided when appending to a file1.
Not to be confused with the type of logs most people are used to: application logs that are meant to be read by humans although application logs are a degenerative case of the log we are talking about2.</description>
    </item>
    <item>
      <title>Notes taken from the Raft paper</title>
      <link>https://poorlydefinedbehaviour.github.io/posts/raft_notes/</link>
      <pubDate>Fri, 04 Mar 2022 17:48:19 -0300</pubDate>
      <guid>https://poorlydefinedbehaviour.github.io/posts/raft_notes/</guid>
      <description>Replicated And Fault Tolerant Raft is a consensus algorithm for managing a replicated log.
The authors claim Raft to be more understandable than Paxos because Raft separates the key elements of consensus
Leader election Log replication Safety and enforces a stronger degree of coherency to reduce the number of states that must be considered.
Raft also includes a new mechanism for changing cluster membership.
What is a consensus algorithm Consensus algorithms allow a collection of machines to work as a coherent group that can survive the failures of some of its members.</description>
    </item>
  </channel>
</rss>
