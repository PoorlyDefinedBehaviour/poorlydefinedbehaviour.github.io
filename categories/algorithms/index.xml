<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Algorithms on </title>
    <link>https://poorlydefinedbehaviour.github.io/categories/algorithms/</link>
    <description>Recent content in Algorithms on </description>
    <image>
      <title></title>
      <url>https://poorlydefinedbehaviour.github.io/papermod-cover.png</url>
      <link>https://poorlydefinedbehaviour.github.io/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.138.0</generator>
    <language>en</language>
    <lastBuildDate>Fri, 06 Oct 2023 20:00:00 -0300</lastBuildDate>
    <atom:link href="https://poorlydefinedbehaviour.github.io/categories/algorithms/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Consistent hashing</title>
      <link>https://poorlydefinedbehaviour.github.io/posts/consistent_hashing/</link>
      <pubDate>Fri, 06 Oct 2023 20:00:00 -0300</pubDate>
      <guid>https://poorlydefinedbehaviour.github.io/posts/consistent_hashing/</guid>
      <description>&lt;p&gt;As the &lt;a href=&#34;https://en.wikipedia.org/wiki/World_Wide_Web&#34;&gt;World Wide Web&lt;/a&gt; became more popular all of sudden a server could receive way more traffic than it could handle causing the server to service requests slowly or to not be able to serve them at all&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. An intuitive solution to this problem is to cache&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; the content served by the servers and allow the clients to fetch content from the caches instead of going to the original server. Several clients communicate with the same cache servers which means that if client &lt;code&gt;1&lt;/code&gt; fetches the contents for the page &lt;code&gt;example.com&lt;/code&gt;, client &lt;code&gt;2&lt;/code&gt; can fetch the same contents from the cache instead of going to the oirignal server if it decides to visit &lt;code&gt;example.com&lt;/code&gt; as well.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Avoid overloading your systems: Request coalescing</title>
      <link>https://poorlydefinedbehaviour.github.io/posts/request_coalescing/</link>
      <pubDate>Sun, 19 Mar 2023 20:54:00 -0300</pubDate>
      <guid>https://poorlydefinedbehaviour.github.io/posts/request_coalescing/</guid>
      <description>&lt;h2 id=&#34;the-problem&#34;&gt;The problem&lt;/h2&gt;
&lt;p&gt;You are developing an application backed by a database, something happens and then several of your users try to access the same content.
Several requests are sent to your backend at almost the same time and your backend hits the database once for each request to fetch the same data.&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://poorlydefinedbehaviour.github.io/posts/request_coalescing/images/users_hitting_backend_at_the_same_time_1.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;fetching-the-data-only-once&#34;&gt;Fetching the data only once&lt;/h2&gt;
&lt;p&gt;If &lt;code&gt;N&lt;/code&gt; requests asking for the same data arrive at the backend at around the same time, the backend could hit the database to fetch the data when the first request arrives and force the other requests to await until the data is fetched. When a response to the request sent to the database arrives at the backend with the data, the data can be shared with the requests that are waiting for it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Logs</title>
      <link>https://poorlydefinedbehaviour.github.io/posts/logs/</link>
      <pubDate>Sat, 30 Apr 2022 16:46:09 -0300</pubDate>
      <guid>https://poorlydefinedbehaviour.github.io/posts/logs/</guid>
      <description>&lt;h1 id=&#34;what-is-a-log&#34;&gt;What is a log&lt;/h1&gt;
&lt;p&gt;A log is just a immutable sequence of records wih strong ordering semantics that can be used to provide durability, replication and to model consensus. It is usually a 0 indexed file that new entries are appended to because expensive disk seeks can usually be avoided when appending to a file&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;img src=&#34;https://user-images.githubusercontent.com/17282221/168452116-a751154f-ec58-4a65-91f5-a90269529963.png&#34; /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Not to be confused with the type of logs most people are used to: application logs that are meant to be read by humans although application logs are a degenerative case of the log we are talking about&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Token bucket</title>
      <link>https://poorlydefinedbehaviour.github.io/posts/token_bucket/</link>
      <pubDate>Sun, 20 Mar 2022 22:21:07 -0300</pubDate>
      <guid>https://poorlydefinedbehaviour.github.io/posts/token_bucket/</guid>
      <description>&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Token_bucket&#34;&gt;Token bucket&lt;/a&gt; is an algorithm that can be used to rate limit requests made or received by a service.&lt;/p&gt;
&lt;h1 id=&#34;how-it-works&#34;&gt;How it works&lt;/h1&gt;
&lt;p&gt;The algorithm is called token bucket because of the way it works: imagine we have a bucket with &lt;code&gt;x&lt;/code&gt; tokens where each accepted request consumes one token from the bucket and a token is added back to the bucket at an interval.&lt;/p&gt;
&lt;p&gt;A bucket with &lt;code&gt;1&lt;/code&gt; token that is refilled each second means the service accepts one request per second.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Notes taken from the Raft paper</title>
      <link>https://poorlydefinedbehaviour.github.io/posts/raft_notes/</link>
      <pubDate>Fri, 04 Mar 2022 17:48:19 -0300</pubDate>
      <guid>https://poorlydefinedbehaviour.github.io/posts/raft_notes/</guid>
      <description>&lt;h1 id=&#34;replicated-and-fault-tolerant&#34;&gt;&lt;strong&gt;R&lt;/strong&gt;eplicated &lt;strong&gt;A&lt;/strong&gt;nd &lt;strong&gt;F&lt;/strong&gt;ault &lt;strong&gt;T&lt;/strong&gt;olerant&lt;/h1&gt;
&lt;p&gt;Raft is a consensus algorithm for managing a replicated log.&lt;/p&gt;
&lt;p&gt;The authors claim Raft to be more understandable than Paxos
because Raft separates the key elements of consensus&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Leader election&lt;/li&gt;
&lt;li&gt;Log replication&lt;/li&gt;
&lt;li&gt;Safety&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and enforces a stronger degree of coherency to reduce the number of states
that must be considered.&lt;/p&gt;
&lt;p&gt;Raft also includes a new mechanism for changing cluster membership.&lt;/p&gt;
&lt;h2 id=&#34;what-is-a-consensus-algorithm&#34;&gt;What is a consensus algorithm&lt;/h2&gt;
&lt;p&gt;Consensus algorithms allow a collection of machines to work as a coherent group
that can survive the failures of some of its members.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
